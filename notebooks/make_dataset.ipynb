{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce827176-390d-4b39-8b65-e64b1b2d0a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import dask_cudf\n",
    "import cudf\n",
    "import numpy as np\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e25cb2-465a-4f63-8b12-d213ecd9e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filepath = '/mnt/DATA/nfs/data/new_marref/MarRef.speciestrain.fasta'\n",
    "output_folder_path = '/mnt/DATA/nfs/data/gene-cnn'\n",
    "label_filepath = '/mnt/DATA/nfs/data/new_marref/MarRef.taxlabel.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13011597-6a6c-4f97-a11b-bc883a52ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer = 1\n",
    "shuffle_data = True\n",
    "perc_of_labs = 1\n",
    "perc_of_data = .1\n",
    "data_splits = {\n",
    "    'train': 0.8,\n",
    "    'val': 0.1,\n",
    "    'test': 0.1,\n",
    "}\n",
    "\n",
    "\n",
    "dataset_name = 'dset-10pD-100pL'\n",
    "split_mers_to_cols = True\n",
    "raw_cols = ['seq', 'id']\n",
    "raw_seq_col = 'seq'\n",
    "raw_lab_col = 'id'\n",
    "\n",
    "random_seed = 42\n",
    "do_random_seed = True\n",
    "\n",
    "\n",
    "label_file_id_col = 'id'\n",
    "label_file_label_cols = [\n",
    "    { 'name_col': 'Species', 'code_col': 'species_code'},\n",
    "    { 'name_col': 'Genus', 'code_col': 'genus_code'},\n",
    "]\n",
    "\n",
    "possible_gene_values = ['A', 'C', 'G', 'T']  \n",
    "max_input_len = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583c78a1-e21f-4a58-9af7-9397ab0ae784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_label_file_label_cols(label_file_label_cols):\n",
    "    for ith in label_file_label_cols:\n",
    "        type_list = [type(val) for key, val in ith.items()]\n",
    "        is_string = sum([x == str for x in type_list])\n",
    "        assert is_string > 0, f\"\\nat least 1 of 'name_col' or 'code_col' must be a string, in 'label_file_label_cols'. \\ncurrently, set as {ith}\"\n",
    "        only_acceptable_types = all([t == type(None) if t != str else True for t in type_list ])\n",
    "        assert only_acceptable_types, f\"\\nthe only acceptable values for 'name_col' or 'code_col' are str type and None type. \\ncurrently, set as {ith}\"\n",
    "    print(\"values of label_file_label_cols are acceptable\")\n",
    "    \n",
    "def validate_perc_of_labs(perc_of_labs):\n",
    "    if type(perc_of_labs) == int:\n",
    "        perc_of_labs = float(perc_of_labs)\n",
    "    assert (type(perc_of_labs) == float) or (type(perc_of_labs) == type(None)), f\"\\n'perc_of_labs' must be a float, integer, or None type. \\ncurently value is '{perc_of_labs}' and type is {type(perc_of_labs)}\"\n",
    "    assert (perc_of_labs > 0) & (perc_of_labs <= 1), f\"\\n'perc_of_labs' must be greater than 0, and less than or equal to 1. \\ncurently value is {perc_of_labs}\"\n",
    "    print(\"value of perc_of_labs is acceptable\")\n",
    "    \n",
    "def validate_perc_of_data(perc_of_data):\n",
    "    if type(perc_of_data) == int:\n",
    "        perc_of_data = float(perc_of_data)\n",
    "    assert (type(perc_of_data) == float) or (type(perc_of_data) == type(None)), f\"\\n'perc_of_labs' must be a float, integer, or None type. \\ncurently value is '{perc_of_data}' and type is {type(perc_of_data)}\"\n",
    "    assert (perc_of_data > 0) & (perc_of_data <= 1), f\"\\n'perc_of_labs' must be greater than 0, and less than or equal to 1. \\ncurently value is {perc_of_data}\"\n",
    "    print(\"value of perc_of_labs is acceptable\")\n",
    "    \n",
    "def validate_data_splits(data_splits):\n",
    "    sum_of_splits = sum([val for key, val in data_splits.items()])\n",
    "    assert sum_of_splits == 1.0, f\"the sum of the values of data_splits must equal 1.0 \\n currenlty they are {[val for key, val in data_splits.items()]} and sum up to {sum_of_splits}\"\n",
    "    print(\"values of data_splits are acceptable\")\n",
    "    \n",
    "def validate_label_file(label_filepath):\n",
    "    assert type(label_filepath) == str, f\"\\n'label_file' must be a string type. \\ncurrently it is type {type(label_filepath)}\"\n",
    "    print(\"value of label_filepath is acceptable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d6da14-317b-4c9e-bc18-6e21307a5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_label_file_label_cols(label_file_label_cols)\n",
    "validate_perc_of_labs(perc_of_labs)\n",
    "validate_perc_of_data(perc_of_data)\n",
    "validate_data_splits(data_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac4d2e-0e35-4cec-abb6-6c32fbd28ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_sep = '>'\n",
    "\n",
    "example_col_name = 'example_id'\n",
    "search_strings = ['/1', '/2']\n",
    "replace_strings = ['', '']\n",
    "split_col_name = 'split'\n",
    "\n",
    "non_mer_regex = '[A-Z]+[ ]{2,}.*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1bde56-77de-461c-8c9c-86e3df74e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits = {x:data_splits[x] for x in sorted(data_splits, key=data_splits.get, reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a0a08-a5e7-49d1-b08c-db01dfe4dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsplit_data_filepath = Path(output_folder_path) / dataset_name / f\"{dataset_name}_unsplit.parquet\"\n",
    "data_label_filepath = Path(output_folder_path) / dataset_name / f\"{dataset_name}_orig_labels.csv\"\n",
    "data_new_label_filepath = Path(output_folder_path) / dataset_name / f\"{dataset_name}_labels.csv\"\n",
    "vocab_filepath = Path(output_folder_path) / dataset_name / f\"{dataset_name}_vocab.txt\"\n",
    "data_splits_filepaths = {}\n",
    "for key, val in data_splits.items():\n",
    "    data_splits_filepaths[key] = Path(output_folder_path) / dataset_name / f\"{dataset_name}_{key}.parquet\"\n",
    "data_splits_filepaths_csv = {}\n",
    "for key, val in data_splits.items():\n",
    "    data_splits_filepaths_csv[key] = Path(output_folder_path) / dataset_name / f\"{dataset_name}_{key}.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0826823-39a4-4329-ac4d-192b3c70369f",
   "metadata": {},
   "source": [
    "make new raw file\n",
    "+ shuffled\n",
    "+ percent of labels\n",
    "+ precent of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132fe4e4-241d-4e59-8463-e68f67f4324e",
   "metadata": {},
   "source": [
    "outline\n",
    "+ part A\n",
    "    1. load fasta file\n",
    "    2. format correctly\n",
    "    3. randomly select percent\n",
    "    4. shuffle\n",
    "    5. save file\n",
    "\n",
    "+ part B\n",
    "    6. format id correctly \n",
    "    7. create id file to reference \n",
    "    8. subset percent of labels\n",
    "    9. save data splits\n",
    "\n",
    "+ part C\n",
    "    9. preprocess dataframes\n",
    "    10. create vocab file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d52249e-f642-40f5-be25-88372c6c48c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('rm -rf ./dask-worker-space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a06cde6-42c0-4d2c-bc16-fd79efdc602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCUDACluster(silence_logs=50)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d89c7-809f-4db6-b676-bfef334fe242",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the dask dashboard can be found here:\\n{client.dashboard_link}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2803949c-e024-4449-ba4c-8ea208c533d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cull_empty_partitions(df):\n",
    "    ll = list(df.map_partitions(len).compute())\n",
    "    df_delayed = df.to_delayed()\n",
    "    df_delayed_new = list()\n",
    "    pempty = None\n",
    "    for ix, n in enumerate(ll):\n",
    "        if 0 == n:\n",
    "            pempty = df.get_partition(ix)\n",
    "        else:\n",
    "            df_delayed_new.append(df_delayed[ix])\n",
    "    if pempty is not None:\n",
    "        df = dask_cudf.from_delayed(df_delayed_new, meta=pempty)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5fa1f-668b-4494-a7db-701baae3ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dask_cudf.read_csv(input_filepath,  # location of raw file\n",
    "                        sep=fasta_sep,  # this is the '>' sign\n",
    "                        names=raw_cols,  # column names\n",
    "                        dtype=str,  # data type\n",
    "                        )\n",
    "\n",
    "df[raw_lab_col] = df[raw_lab_col].shift()\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f985b6-c5d2-4327-b63d-4e1dc61c241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (perc_of_data != None) & (perc_of_data < 1.0):\n",
    "    def subset_data(df):\n",
    "        df['random_num'] = ''\n",
    "        num_random = df.shape[0]\n",
    "        if do_random_seed:\n",
    "            np.random.seed(random_seed)\n",
    "        df['random_num'] = np.random.uniform(size=num_random)\n",
    "        keep_mask = df['random_num'] < perc_of_data\n",
    "        df = df[keep_mask]\n",
    "        df = df.drop(columns=['random_num'])\n",
    "        return df\n",
    "    df = df.map_partitions(subset_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c2d6f9-12b8-435b-a527-9258682aff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shuffle_data:\n",
    "    def random_shuffle(df):\n",
    "        df['random_num'] = ''\n",
    "        num_random = df.shape[0]\n",
    "        if do_random_seed:\n",
    "            np.random.seed(random_seed)\n",
    "        df['random_num'] = np.random.uniform(size=num_random)\n",
    "        df = df.set_index(df['random_num'] ).sort_index().reset_index(drop=True)\n",
    "        return df\n",
    "    df = df.map_partitions(random_shuffle)\n",
    "    df = df.drop(columns='random_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64ce558-cf92-4795-984d-041cb4a5d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cull_empty_partitions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1b614-2998-426e-8e50-46284e39a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(unsplit_data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ba4f4-972f-4fb7-8cd8-5ed143889708",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6104cf8-d10b-4705-9f7a-1160aff15723",
   "metadata": {},
   "source": [
    "## part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de7a03-54a2-47ab-a284-d44790e19a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = []\n",
    "keep_cols.append(label_file_id_col)\n",
    "for ith in label_file_label_cols:\n",
    "    keep_cols.append(ith['name_col'])\n",
    "    keep_cols.append(ith['code_col'])\n",
    "    \n",
    "label_df = dask_cudf.read_csv(label_filepath, sep='\\t', dtype=str, usecols=keep_cols)\n",
    "label_df.to_csv(data_label_filepath, index=False, single_file=True)\n",
    "label_df = label_df.compute().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aac945-b655-438f-88c8-926a4aa424a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cea439-5b04-487d-ad61-0785588e5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dask_cudf.read_parquet(unsplit_data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca114b71-f844-4b69-adde-441fea1c1493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106fccd8-e91d-4bc2-af49-ff359ff28695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(example_id='')\n",
    "df['example_id'] = df[label_file_id_col]\n",
    "\n",
    "search_strings = ['/1', '/2']\n",
    "replace_strings = ['', '']\n",
    "\n",
    "def extract_example(df):\n",
    "    df['example_id'] = df['example_id'].str.replace(pat=search_strings, repl=replace_strings, n=None)\n",
    "    return df\n",
    "\n",
    "df = df.map_partitions(extract_example, meta=extract_example(df.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a47477b-dd21-4d82-8b0e-8d705a7f07b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30937ff-792b-4361-853a-88fec86e65ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(df):\n",
    "    df[raw_lab_col] = df[raw_lab_col].str.split('|').list.get(-1).str.split('-').list.get(0).str.split('_').list.get(0)\n",
    "    return df\n",
    "\n",
    "df = df.map_partitions(extract_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4a9223-ceba-4d40-8e59-c5f7c2ea65b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e742ad-097f-4758-aa45-89c8ab3563de",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_cols = [x['code_col'] for x in label_file_label_cols]\n",
    "label_df_merge_cols = [label_file_id_col] + code_cols\n",
    "label_df_merge_cols\n",
    "\n",
    "def merge_label_codes(df):\n",
    "    merge_label_df = label_df[label_df_merge_cols]\n",
    "    df = df.merge(merge_label_df, how='left', on=label_file_id_col)\n",
    "    return df\n",
    "\n",
    "df = df.map_partitions(merge_label_codes, meta=merge_label_codes(df.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b9885-ece6-435b-bd66-145039a64856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720740d7-fea7-4e68-965f-22afda3f65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check to see if there are any missing IDs\n",
    "def check_na(df):\n",
    "    \n",
    "    isna_mask = df.isna().all(axis=1)\n",
    "    df = df[isna_mask]\n",
    "    return df\n",
    "\n",
    "na_df = df.map_partitions(check_na, meta=check_na(df.head())).compute()\n",
    "assert na_df.shape[0] == 0, f\"you have missing ID values!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04dd771-f64e-4fa4-a35b-19c805337198",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (perc_of_labs != None) & (perc_of_labs < 1.0):\n",
    "    label_df['random_num'] = ''\n",
    "    num_random = label_df.shape[0]\n",
    "    if do_random_seed:\n",
    "            np.random.seed(random_seed)\n",
    "    label_df['random_num'] = np.random.uniform(size=num_random)\n",
    "    keep_mask = label_df['random_num'] < perc_of_labs\n",
    "    sub_label_df = label_df[keep_mask].copy()\n",
    "    sub_label_df = sub_label_df.drop(columns=['random_num'])\n",
    "    label_df = label_df.drop(columns=['random_num'])\n",
    "\n",
    "    def subset_labels(df):\n",
    "            df = df.set_index(label_file_id_col)\n",
    "            df = df.loc[sub_label_df[label_file_id_col].unique()]\n",
    "            df = df.reset_index()\n",
    "            return df\n",
    "\n",
    "    df = df.map_partitions(subset_labels, meta=subset_labels(df.head(100)))\n",
    "    \n",
    "    sub_label_df.to_csv(str(data_label_filepath).replace('.csv', '_subset.csv'), index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e238c82a-7865-4f48-adb0-4fb4fcf9e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0a94ad-a9ce-4514-b25a-1d173ae70ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shuffle_data:\n",
    "    def random_shuffle(df):\n",
    "        df['random_num'] = ''\n",
    "        num_random = df.shape[0]\n",
    "        if do_random_seed:\n",
    "            np.random.seed(random_seed)\n",
    "        df['random_num'] = np.random.uniform(size=num_random)\n",
    "        df = df.set_index(df['random_num'] ).sort_index().reset_index(drop=True)\n",
    "        return df\n",
    "    df = df.map_partitions(random_shuffle)\n",
    "    df = df.drop(columns='random_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a258161-6054-42dd-b7be-ac0eae99d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check to see if there are any missing IDs\n",
    "def check_na(df):\n",
    "    \n",
    "    isna_mask = df.isna().all(axis=1)\n",
    "    df = df[isna_mask]\n",
    "    return df\n",
    "\n",
    "na_df = df.map_partitions(check_na, meta=check_na(df.head())).compute()\n",
    "assert na_df.shape[0] == 0, f\"you have missing ID values!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5031e-1637-45c8-9a3c-74ecc750aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.copy().assign(count=1)\n",
    "lab_md = []\n",
    "for code_col in code_cols:\n",
    "    temp2 = temp_df[[code_col] + ['count']]\n",
    "    temp2 = temp2.groupby(code_col).sum()\n",
    "    temp2['lab_type'] = code_col\n",
    "    temp2['lab_code'] = temp2.index\n",
    "    temp2 = temp2.reset_index(drop=True)\n",
    "    temp2 = temp2[['lab_type', 'lab_code', 'count']]\n",
    "    lab_md.append(temp2.compute())\n",
    "lab_md = cudf.concat(lab_md, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebbe85e-2bdb-4b34-acc2-27cd2740a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_md['lab_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0e815-36c0-4078-a595-c0464cb2ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829e3db-b56a-46db-9f52-f41d38640d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################################################\n",
    "#################### CLASS RELABELING: NEED TO UPDATE. CURRENLT HARDCODED SPECIES AND GENUS. MUST REFACTOR TO GENERALIZE #################################\n",
    "#########################################################################################################################################################\n",
    "cur_lab_df = df[code_cols].drop_duplicates().copy().compute()\n",
    "spec_rename_df = cur_lab_df[['species_code']].drop_duplicates().astype(int, errors='ignore').sort_values('species_code').reset_index(drop=True).reset_index().rename(columns={'index':'new_species_code'}).copy()\n",
    "gen_rename_df = cur_lab_df[['genus_code']].drop_duplicates().astype(int, errors='ignore').sort_values('genus_code').reset_index(drop=True).reset_index().rename(columns={'index':'new_genus_code'}).copy()\n",
    "def rename_labs(df):\n",
    "    df = df.merge(spec_rename_df, how='left', on='species_code')\n",
    "    df = df.merge(gen_rename_df, how='left', on='genus_code')\n",
    "    df = df.drop(columns=['species_code', 'genus_code'])\n",
    "    df = df.rename(columns={'new_genus_code':'genus_code', 'new_species_code':'species_code'})\n",
    "    return df\n",
    "df = df.map_partitions(rename_labs, meta=rename_labs(df.head(100)))\n",
    "\n",
    "orig_label_df = cudf.read_csv(data_label_filepath)\n",
    "orig_label_df = df[['id']].copy().drop_duplicates().merge(orig_label_df, how='left', on='id')\n",
    "new_label_df = rename_labs(orig_label_df).dropna().compute()\n",
    "_ = new_label_df.to_csv(data_new_label_filepath, index=False)\n",
    "#########################################################################################################################################################\n",
    "#########################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda12b6a-c416-44a8-8731-a778cbe8afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_examples = df['example_id'].unique().to_frame()\n",
    "unq_examples = unq_examples.assign(split='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46937593-a19b-4e29-b154-d17d53b94237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d0693-9ccc-4342-ab39-04dbe9429349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spit_val(df):\n",
    "    df['random_num'] = ''\n",
    "    num_random = df.shape[0]\n",
    "    if do_random_seed:\n",
    "        np.random.seed(random_seed)\n",
    "    df['random_num'] = np.random.uniform(size=num_random)\n",
    "    \n",
    "    cur_lthresh = 0\n",
    "    for i, (split_name, split_perc) in enumerate(data_splits.items()):\n",
    "        if i == 0:\n",
    "            # set stuff\n",
    "            split_mask = df['random_num'] < split_perc\n",
    "            df['split'][split_mask] = split_name\n",
    "            cur_lthresh += split_perc\n",
    "        else:\n",
    "            cur_uthresh = cur_lthresh + split_perc\n",
    "            split_mask = (df['random_num'] < cur_uthresh) & (df['random_num'] >= cur_lthresh)\n",
    "            df['split'][split_mask] = split_name\n",
    "            cur_lthresh += split_perc\n",
    "    \n",
    "    df = df.drop(columns=['random_num'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dd45c7-969f-44b2-8b1c-8abc71f909cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_examples = unq_examples.map_partitions(add_spit_val, meta=add_spit_val(unq_examples.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8109dbb2-ca56-45ae-a300-014312c27b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(unq_examples, how='left', on='example_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34e023-fcd8-40a0-9ad5-35f68e27d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shuffle_data:\n",
    "    def random_shuffle(df):\n",
    "        df['random_num'] = ''\n",
    "        num_random = df.shape[0]\n",
    "        if do_random_seed:\n",
    "            np.random.seed(random_seed)\n",
    "        df['random_num'] = np.random.uniform(size=num_random)\n",
    "        df = df.set_index(df['random_num'] ).sort_index().reset_index(drop=True)\n",
    "        return df\n",
    "    df = df.map_partitions(random_shuffle)\n",
    "    df = df.drop(columns='random_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd9298-4da7-4e49-af6f-cc7064ccf1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606c1d0f-89ef-473b-a07a-c72b0602e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_name, split_filepath in data_splits_filepaths.items():\n",
    "    # print(split_name)\n",
    "    def extract_split(df):\n",
    "        df = df[df[split_col_name] == split_name]\n",
    "        df = df.drop(columns=['example_id', 'id', 'split'])\n",
    "        df = df.reset_index(drop=True)\n",
    "        return df\n",
    "    temp_df = df.map_partitions(extract_split, meta=extract_split(df.head()))\n",
    "    temp_df = cull_empty_partitions(temp_df)\n",
    "    _ = temp_df.to_parquet(split_filepath)\n",
    "    \n",
    "    # create label metadata: count of each label\n",
    "    temp_df = temp_df.assign(count=1)\n",
    "    lab_md_filepath = str(split_filepath).replace('.parquet', '_lab_md.csv')\n",
    "    lab_md = []\n",
    "    for code_col in code_cols:\n",
    "        temp2 = temp_df[[code_col] + ['count']]\n",
    "        temp2 = temp2.groupby(code_col).sum()\n",
    "        temp2['lab_type'] = code_col\n",
    "        temp2['lab_code'] = temp2.index\n",
    "        temp2 = temp2.reset_index(drop=True)\n",
    "        temp2 = temp2[['lab_type', 'lab_code', 'count']]\n",
    "        lab_md.append(temp2.compute())\n",
    "    lab_md = cudf.concat(lab_md, ignore_index=True)\n",
    "    \n",
    "    _ = lab_md.to_csv(lab_md_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152000d-c5f8-4c5d-9ad3-22ae0631b373",
   "metadata": {},
   "outputs": [],
   "source": [
    "del temp_df, unq_examples, label_df, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb604883-b4a7-45f4-baf6-ade6f92285c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (perc_of_labs != None) & (perc_of_labs < 1.0):\n",
    "    del sub_label_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cd1e83-89cb-4e0f-8fb0-d5215df5028d",
   "metadata": {},
   "source": [
    "## part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6bb6a0-2570-46ca-9f20-3e6cc9bf6710",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_data = '\\n' + '\\n'.join(possible_gene_values) #+ '\\n' + sos_token + '\\n' + eos_token\n",
    "\n",
    "raw_vocab_list = vocab_data.split('\\n')\n",
    "token_vocab_list = [str(x) for x in list(range(len(raw_vocab_list)))]\n",
    "# token_vocab_list = list(range(len(raw_vocab_list)))\n",
    "\n",
    "\n",
    "vocab_data = vocab_data + '\\n[UNK]' + '\\n[MASK]'\n",
    "open(vocab_filepath, 'w').write(vocab_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad9e8a-1134-41e4-a611-af27189000a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cff0df-d5fc-4f34-9ec9-f89b065158a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaf09e5-7b47-4503-8875-6d855ef4dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_digits(df):\n",
    "    df[raw_seq_col] = df[raw_seq_col].str.replace(raw_vocab_list[1::], token_vocab_list[1::], regex=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb168aa-c17a-4d67-9df2-4d72b8c459be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_non_digits(df):\n",
    "    df = df[df[raw_seq_col].str.isdigit() == True]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ad12e-01c9-4f9e-a944-8fea54eb6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_gene_values = []\n",
    "func_possible_gene_values = token_vocab_list[1::].copy()\n",
    "func_possible_gene_values += ['0']\n",
    "for gene_val in func_possible_gene_values:\n",
    "    replace_gene_values.append(gene_val + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b43dd-3dd4-4ce3-8ae8-73d6a481ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_gene_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae824de2-b44f-481f-8bcb-63604bfdbfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_possible_gene_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e847506-4fa6-4ec9-8e50-c830ce58a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_whitespace(df):\n",
    "    df[raw_seq_col] = df[raw_seq_col].str.replace(func_possible_gene_values, replace_gene_values, regex=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3993b03-c493-4239-b0c2-80ecaacb7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(df):\n",
    "    df[raw_seq_col] = df[raw_seq_col].str.pad(width=max_input_len, side='right', fillchar='0')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243aea05-ac51-4a16-b18e-7d383f278fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_label_col_names = [x['code_col'] for x in label_file_label_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b482dc-04af-412a-96c9-1ad528c51806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_int_dtype(df):\n",
    "    for out_col in out_label_col_names:\n",
    "        df[out_col] = df[out_col].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff74c7f-a525-4f27-83df-bd1b63b4880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_dna_seq(df):\n",
    "    \n",
    "    # df = add_sos_eos(df)\n",
    "    df = to_digits(df)\n",
    "    df = drop_non_digits(df)\n",
    "    df = add_padding(df)\n",
    "    df = add_whitespace(df)\n",
    "    \n",
    "    seq_ser = df[raw_seq_col].copy()\n",
    "\n",
    "    seq_ser = seq_ser.str.split(expand=True)\n",
    "    \n",
    "    seq_ser = seq_ser.replace(' ', '')\n",
    "    seq_ser = seq_ser.fillna(0)\n",
    "    \n",
    "    seq_ser = seq_ser.astype('float32')\n",
    "    \n",
    "    old_col_names = seq_ser.columns\n",
    "    new_col_names = [f\"{raw_seq_col}_{str(old_col_name)}\" for old_col_name in old_col_names]\n",
    "    seq_ser = seq_ser.rename(columns={x:y for x,y in zip(old_col_names, new_col_names)})\n",
    "    \n",
    "    for out_col in out_label_col_names:\n",
    "        seq_ser[out_col] = df[out_col].copy()#.astype('int64')\n",
    "        \n",
    "    df = seq_ser\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca79317-c536-4b71-9398-fc7fb33b63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_name, split_filepath in data_splits_filepaths.items():\n",
    "    out_pathname = data_splits_filepaths_csv[split_name]\n",
    "    df = dask_cudf.read_parquet(split_filepath)\n",
    "    df = df.map_partitions(split_dna_seq, meta=split_dna_seq(df.head(100)))\n",
    "    _ = df.to_csv(out_pathname, index=False, single_file=True)\n",
    "    del df\n",
    "    # pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdc55b-fad4-45aa-b1f9-5a33d771bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"processes finished, shutting down cluster...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecc6865-77fd-45d0-a129-84a1a9b52415",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333e3ccd-e2d4-4339-afe5-a17cb1601a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cluster shutdown, deleting client...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25197f3-2daa-42ee-852b-5d29fe556e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "del client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca394a-d38f-4a20-8a5f-340058ca3b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

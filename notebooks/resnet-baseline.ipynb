{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69eafe9-2909-4dea-bac8-568a2d1bf5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.utils.layer_utils import count_params\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f85c61-d287-471d-890d-3f1777e771b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = keras.mixed_precision.Policy(\"mixed_float16\")\n",
    "keras.mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09ef67-091e-4713-bbd8-070e5152ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_folder_path = '/mnt/DATA/nfs/data/gene-nn-survey'\n",
    "output_folder_path = '/mnt/DATA/nfs/data/gene-cnn'\n",
    "dataset_name = 'dset-10pD-100pL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb55891b-ab8b-4e13-aed7-fdcd0c65fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"gene-cnn-2\"\n",
    "run_name = 'resnet-baseline'\n",
    "description = 'resnet 50; 25m params; 10% data; 100% labels; species only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142fec3-a3e6-44ba-a877-fed04e167d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits = {\n",
    "    'train': 0.8,\n",
    "    'val': 0.1,\n",
    "    'test': 0.1,\n",
    "}\n",
    "\n",
    "label_file_id_col = 'id'\n",
    "label_file_label_cols = [\n",
    "    { 'name_col': 'Species', 'code_col': 'species_code'},\n",
    "    { 'name_col': 'Genus', 'code_col': 'genus_code'},\n",
    "]\n",
    "\n",
    "labels_to_use = 'species'\n",
    "\n",
    "max_input_len = 150\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 3\n",
    "learning_rate = .0003\n",
    "\n",
    "tf_logs_dir = 'tf_logs/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e18f52-ff28-404b-acbb-ff7a3be1ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_seq_len = max_input_len\n",
    "first_filter_size = 64\n",
    "res_block_reps = [3, 4, 6, 3]\n",
    "activation = 'relu'\n",
    "gen_filter_size = 3\n",
    "bn_momen = 0.6\n",
    "LAST_ACTIVATION = 'softmax'\n",
    "\n",
    "CENTER = True\n",
    "SCALE = False\n",
    "EPSILON = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9a09f-8c1d-4cbf-9d08-fe41648e3fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "    \"description\": description,\n",
    "    \"output_folder_path\": output_folder_path,\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"label_file_id_col\": label_file_id_col,\n",
    "    \"label_file_label_cols\": label_file_label_cols,\n",
    "    \"max_input_len\": max_input_len,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"EPOCHS\": EPOCHS,\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"first_filter_size\": first_filter_size,\n",
    "    \"res_block_reps\": res_block_reps,\n",
    "    \"activation\": activation,\n",
    "    \"gen_filter_size\": gen_filter_size,\n",
    "    \"bn_momen\": bn_momen,\n",
    "    \"LAST_ACTIVATION\": LAST_ACTIVATION,\n",
    "    \"CENTER\": CENTER,\n",
    "    \"SCALE\": SCALE,\n",
    "    \"EPSILON\": EPSILON,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a54c3-eee3-4f03-9708-5727cc6156a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits = {x:data_splits[x] for x in sorted(data_splits, key=data_splits.get, reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b5973c-6daf-42c7-89a2-4f37beabc1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsplit_data_filepath = Path(output_folder_path) / dataset_name / f\"{dataset_name}_unsplit.parquet\"\n",
    "data_label_filepath = Path(output_folder_path) / dataset_name / f\"{dataset_name}_labels.csv\"\n",
    "vocab_filepath = Path(output_folder_path) / dataset_name / f\"{dataset_name}_vocab.txt\"\n",
    "data_splits_filepaths = {}\n",
    "for key, val in data_splits.items():\n",
    "    data_splits_filepaths[key] = Path(output_folder_path) / dataset_name / f\"{dataset_name}_{key}.parquet\"\n",
    "data_splits_filepaths_csv = {}\n",
    "for key, val in data_splits.items():\n",
    "    data_splits_filepaths_csv[key] = Path(output_folder_path) / dataset_name / f\"{dataset_name}_{key}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e42518a-2d11-4a4f-9fe3-ee0ab4c45790",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (labels_to_use == 'genus') or (labels_to_use == 'species') or (labels_to_use == 'both'), f\"\\nvariable 'labels_to_use' must be 'genus' 'species' or 'both' \\n currently set as {labels_to_use}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318c12ba-ddd1-40a3-a4b2-5e792b9a9186",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_vocab_list = open(vocab_filepath, 'r').read().split('\\n')\n",
    "token_vocab_list = list(range(len(raw_vocab_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e14120-72f4-4eba-ab17-101b07b021e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3090c1ed-220d-4bfd-bc84-caccbb20278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(raw_vocab_list) - 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cebf56-f039-4600-955b-5f4320d5e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [x['code_col'] for x in label_file_label_cols]\n",
    "all_classes = (pd.read_csv(data_label_filepath)[label_cols].max() + 1).tolist()\n",
    "if labels_to_use == 'species':\n",
    "    N_CLASSES = [all_classes[0]]\n",
    "elif labels_to_use == 'genus':\n",
    "    N_CLASSES = [all_classes[0]]\n",
    "else:\n",
    "    N_CLASSES = all_classes\n",
    "\n",
    "N_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9145ae-d118-4721-a55a-b03dd5215064",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config['N_CLASSES'] = N_CLASSES\n",
    "wandb.config['vocab_size'] = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0549384-aa7a-428a-9603-efa9defd5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = pd.read_csv(data_splits_filepaths_csv['train'], nrows=5).columns.tolist()\n",
    "\n",
    "input_cols = all_cols.copy()\n",
    "for label_col in label_cols:\n",
    "    input_cols.remove(label_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630761f-7005-418b-bb43-63a294672170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_ds = tf.data.experimental.CsvDataset(\n",
    "    str(data_splits_filepaths_csv['train']), [tf.float32] * len(input_cols) + [tf.int32] * len(label_cols), header=True, \n",
    ").batch(BATCH_SIZE)\n",
    "val_ds = tf.data.experimental.CsvDataset(\n",
    "    str(data_splits_filepaths_csv['val']), [tf.float32] * len(input_cols) + [tf.int32] * len(label_cols), header=True, \n",
    ").batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa08ca-3a5f-45af-8cbd-6268cd81f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_ds.unbatch().batch(4).take(1).get_single_element())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc56872-bb40-4dd7-bb36-2441c73a724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if labels_to_use == 'species':\n",
    "    @tf.function\n",
    "    def preprocess(*all_cols):\n",
    "        inps = tf.transpose(all_cols[:(len(label_cols) * -1)])\n",
    "        inps = tf.expand_dims(inps, 1)\n",
    "        inps = tf.expand_dims(inps, -1)\n",
    "        labs = all_cols[(len(label_cols) * -1)::]\n",
    "        lab1 = tf.one_hot(labs[0], depth=N_CLASSES[0])\n",
    "        return inps, lab1\n",
    "elif labels_to_use == 'genus':\n",
    "    @tf.function\n",
    "    def preprocess(*all_cols):\n",
    "        inps = tf.transpose(all_cols[:(len(label_cols) * -1)])\n",
    "        inps = tf.expand_dims(inps, 1)\n",
    "        inps = tf.expand_dims(inps, -1)\n",
    "        labs = all_cols[(len(label_cols) * -1)::]\n",
    "        lab2 = tf.one_hot(labs[1], depth=N_CLASSES[0])\n",
    "        return inps, lab2\n",
    "else:\n",
    "    @tf.function\n",
    "    def preprocess(*all_cols):\n",
    "        inps = tf.transpose(all_cols[:(len(label_cols) * -1)])\n",
    "        inps = tf.expand_dims(inps, 1)\n",
    "        inps = tf.expand_dims(inps, -1)\n",
    "        labs = all_cols[(len(label_cols) * -1)::]\n",
    "        lab1 = tf.one_hot(labs[0], depth=N_CLASSES[0])\n",
    "        lab2 = tf.one_hot(labs[1], depth=N_CLASSES[1])\n",
    "        return inps, (lab1, lab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822e88fb-929f-4543-9c0c-428b9fdc5208",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_options = tf.data.Options()\n",
    "tf_options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83705055-9c9f-4ef1-91c8-036deaa5ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use prefetch() to pre-compute preprocessed batches on the fly on our CPU.\n",
    "processed_train_ds = train_ds.map(\n",
    "    preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
    ").prefetch(tf.data.AUTOTUNE).with_options(tf_options)\n",
    "processed_val_ds = val_ds.map(\n",
    "    preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
    ").prefetch(tf.data.AUTOTUNE).with_options(tf_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc592495-96df-43ba-8367-1f69187023ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a single input example.\n",
    "print(processed_val_ds.take(1).get_single_element())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085eb77-3971-4503-8a64-e3a0ba144b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(dtype=tf.float32, shape=(1, max_input_len, 1,))\n",
    "outputs = tf.math.multiply(inputs, 1/vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154be4d5-c2fc-4ba7-a801-10002c982902",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=wandb.config['learning_rate'])\n",
    "wandb.config['optimizer'] = optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cee9d9-fe40-4d87-91ed-89a3bdf99ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirrored_strategy = tf.distribute.MultiWorkerMirroredStrategy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32574505-e1f9-4480-a391-19c3fec36d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "\n",
    "    assert (gen_filter_size % 2) != 0, f\"gen_filter_size must be an odd number. currently set to {gen_filter_size}\"\n",
    "    pad_size = int((max_seq_len - (max_seq_len - (gen_filter_size - 1))) / 2)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(first_filter_size, (1, 7), padding='same', strides=2, activation=None)(inputs)\n",
    "    outputs = tf.keras.layers.BatchNormalization(momentum=bn_momen, scale=SCALE, center=CENTER, epsilon=EPSILON)(outputs)\n",
    "    outputs = tf.keras.layers.Activation(activation)(outputs)\n",
    "\n",
    "    outputs = tf.keras.layers.MaxPool2D(pool_size=(1,3), padding='same', strides=2)(outputs)\n",
    "\n",
    "    cur_filter_size = first_filter_size \n",
    "    for br_i, block_rep in enumerate(res_block_reps):\n",
    "        # print(block_rep)\n",
    "        for r_i in np.arange(block_rep):\n",
    "            # print(f\"\\t{r_i}\")\n",
    "\n",
    "\n",
    "            # print(outputs.shape)\n",
    "            if (r_i == 0) & (br_i == 0):\n",
    "                outputs = tf.keras.layers.Conv2D(cur_filter_size * 4, (1, 1), padding='same', strides=1, activation=None)(outputs)\n",
    "                outputs = tf.keras.layers.BatchNormalization(momentum=bn_momen, scale=SCALE, center=CENTER, epsilon=EPSILON)(outputs)\n",
    "                skip_layer = outputs\n",
    "            elif r_i == 0:\n",
    "                cur_filter_size *= 2\n",
    "                outputs = tf.keras.layers.Conv2D(cur_filter_size * 4, (1, 1), padding='same', strides=1, activation=None)(outputs)\n",
    "                outputs = tf.keras.layers.BatchNormalization(momentum=bn_momen, scale=SCALE, center=CENTER, epsilon=EPSILON)(outputs)\n",
    "                skip_layer = outputs\n",
    "            else:\n",
    "                skip_layer = outputs\n",
    "\n",
    "\n",
    "            # print(outputs.shape)\n",
    "            outputs = tf.keras.layers.Conv2D(cur_filter_size, (1, 1), padding='same', strides=1, activation=None)(outputs)\n",
    "            outputs = tf.keras.layers.BatchNormalization(momentum=bn_momen, scale=SCALE, center=CENTER, epsilon=EPSILON)(outputs)\n",
    "            outputs = tf.keras.layers.Activation(activation)(outputs)\n",
    "\n",
    "            # print(outputs.shape)\n",
    "            outputs = tf.keras.layers.Conv2D(cur_filter_size, (1, gen_filter_size), strides=1, activation=None)(skip_layer)\n",
    "            outputs = tf.keras.layers.ZeroPadding2D((0, pad_size))(outputs)\n",
    "            outputs = tf.keras.layers.BatchNormalization(momentum=bn_momen, scale=SCALE, center=CENTER, epsilon=EPSILON)(outputs)\n",
    "            outputs = tf.keras.layers.Activation(activation)(outputs)\n",
    "\n",
    "            # print(outputs.shape)\n",
    "            outputs = tf.keras.layers.Conv2D(cur_filter_size * 4, (1, 1), padding='same', strides=1, activation=None)(outputs)\n",
    "            outputs = tf.keras.layers.BatchNormalization(momentum=bn_momen, scale=SCALE, center=CENTER, epsilon=EPSILON)(outputs)\n",
    "\n",
    "            # print(outputs.shape)\n",
    "            outputs = tf.keras.layers.Add()([outputs, skip_layer])\n",
    "            outputs = tf.keras.layers.Activation(activation)(outputs)\n",
    "            # print(outputs.shape)\n",
    "\n",
    "\n",
    "\n",
    "    outputs = tf.keras.layers.GlobalAveragePooling2D()(outputs)\n",
    "    \n",
    "    prediction_head = []\n",
    "    for n_class in N_CLASSES:\n",
    "        prediction_head.append(keras.layers.Dense(n_class, activation=LAST_ACTIVATION)(outputs))\n",
    "\n",
    "    model = tf.keras.Model(inputs, prediction_head)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\"categorical_accuracy\",],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0fa167-3f3a-454b-9e23-6252141ec5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0422c0-0a51-4e01-b120-e0fde94a67dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_param_count = count_params(model.trainable_weights)\n",
    "non_trainable_param_count = count_params(model.non_trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37ef2e7-cd91-4556-a301-14d856a1fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf8d6b-9fcb-4607-b698-9c8003e7d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config['trainable_param_count'] = trainable_param_count\n",
    "wandb.config['non_trainable_param_count'] = non_trainable_param_count\n",
    "wandb.config['total_param_count'] = non_trainable_param_count + trainable_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a412f5-923b-4b0e-a733-2e1e6759c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "                        monitor='val_loss',\n",
    "                        patience=EPOCHS,\n",
    "                        restore_best_weights=True\n",
    "                    )\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=tf_logs_dir,\n",
    "    histogram_freq=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cb7d6a-b986-4efe-bfbe-99d74463c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af614b-4a55-4f59-b98a-5439557f3f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=project_name,\n",
    "          name=run_name,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe84e78-7ace-415d-b081-31a5787ff71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "with run:\n",
    "    model.fit(\n",
    "        processed_train_ds, validation_data=processed_val_ds, \n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[\n",
    "            earlystopping_cb, \n",
    "            tensorboard_cb, \n",
    "            WandbCallback(),\n",
    "        ]\n",
    "    )\n",
    "    # model.evaluate(processed_val_ds)\n",
    "    wandb.config.update(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85691ef5-54f4-49af-a4b4-5f313d69998a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
